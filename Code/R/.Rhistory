?read.FASTA()
#read the file in as AABin
data <- read.FASTA(filename,type="AA", as.character.AAbin())
#read the file in as AABin
data <- read.FASTA(filename,type="AA", as.character.AAbin=TRUE)
#read the file in as AABin
data <- read.FASTA(filename,type="AA", as.character="AAbin")
#read the file in as AABin
data <- read.FASTA(filename,type="AA", as.character=TRUE )
#read the file in as AABin
data <- read.FASTA(filename,type="AA" )
View(data)
?dist.aa()
#quantify the differences between sequences
check <-dist.aa(data, pairwise.deletion = FALSE, scaled = FALSE)
#quantify the differences between sequences
check <-dist.aa(data, pairwise.deletion = TRUE, scaled = FALSE, as.matrix=TRUE)
#quantify the differences between sequences
check <-dist.aa(data, pairwise.deletion = TRUE, scaled = FALSE, as.numeric=TRUE)
#quantify the differences between sequences
distance_matrix <- dist.aa(data)
#quantify the differences between sequences
data_matrix <- as.matrix(data)
dist_aa <- dist(data_matrix)
check <- dist(data_matrix)
str(check)
# turn the distances into variables (principle component values)
fit <- cmdscale(check,eig=TRUE, k=4)
mydata <- as.data.frame(fit$points)
mydata$sample <- row.names(mydata)
#colour pallete
col_vector <- c('gold','royalblue2', 'mediumorchid3', 'firebrick1','cyan','darkorange','seagreen', 'pink', 'gray75')
#shape pallete
shape_vector <-c(17,19,15)
#Plotting MDS
p <- ggplot(mydatainfo,aes(x=V1,y=V2,text=sample, colour=geo_name,
shape=type)) +
geom_point(size=4, alpha=0.4) +
theme_pubr() +
scale_shape_manual(values=shape_vector, name="EBV type") +
scale_colour_manual(values = col_vector, name="Geo tag") +
theme(legend.position = "right") +
xlab('MDS1') + ylab("MDS2")
#Plotting MDS
p <- ggplot(mydatainfo,aes(x=V1,y=V2,text=sample)) +
geom_point(size=4, alpha=0.4) +
theme_pubr() +
#scale_shape_manual(values=shape_vector, name="EBV type") +
#scale_colour_manual(values = col_vector, name="Geo tag") +
theme(legend.position = "right") +
xlab('MDS1') + ylab("MDS2")
#Plotting MDS
p <- ggplot(mydata,aes(x=V1,y=V2,text=sample)) +
geom_point(size=4, alpha=0.4) +
theme_pubr() +
#scale_shape_manual(values=shape_vector, name="EBV type") +
#scale_colour_manual(values = col_vector, name="Geo tag") +
theme(legend.position = "right") +
xlab('MDS1') + ylab("MDS2")
p
# Silhouette Method
library(cluster)
# Silhouette Method
install.packages("library")
# Silhouette Method
install.packages("cluster")
install.packages("cluster")
install.packages("cluster")
install.packages("cluster")
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, dist(dist_aa))$avg.width
}
hc <- hclust(as.dist(dist_aa), method = "ward.D")
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, dist(dist_aa))$avg.width
}
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, dist(data_matrix))$avg.width
}
hc <- hclust(as.dist(data_matrix), method = "ward.D")
# Silhouette Method
library(cluster)
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, dist(data_matrix))$avg.width
}
hc <- hclust(as.dist(fit), method = "ward.D")
hc <- hclust(as.dist(check), method = "ward.D")
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, dist(check))$avg.width
}
class(distance_matrix)
class(data_matrix)
dim(data_matrix)
class(dist_aa)
dim(dist_aa)
hc <- hclust(as.dist(dist_aa), method = "ward.D")
# Silhouette Method
library(cluster)
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, dist(dist_aa))$avg.width
}
if (!inherits(dist_aa, "dist")) {
dist_aa <- as.dist(dist_aa)
}
# Silhouette Method
library(cluster)
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, dist(dist_aa))$avg.width
}
class(check)
dim(check)
#clear your environment
rm(list = ls())
#take packages you need out of the library
library(ape)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggpubr)
#these packages are not necessary, but I like interactive clustering where I can click on points and see the sample names!
#install.packages("ggrepel")
library("ggrepel")
#install.packages("plotly")
library("plotly")
#install.packages("htmlwidgets")
library("htmlwidgets")
#make sure you set the correct working directory
#change the file name below to address your MSA fasta file
filename <- "gB_genbank_aligned.fasta"
#read the file in as AABin
data <- read.FASTA(filename,type="AA")
#create a distance matrix
sequences <- as.character(data)
distance_matrix <- dist.aa(sequences)
#read the file in as AABin
data <- read.FASTA(filename,type="AA")
#create a distance matrix
data_matrix <- as.matrix(data)
check <- dist(data_matrix)
#check if NA values are created - delete if found
for (i in 1:nrow(check)) {
for (j in 1:ncol(check)) {if (check[i,j]=="NaN") {check[i,j]<-0 }}}
# turn the distances into variables (principle component values)
fit <- cmdscale(check,eig=TRUE, k=4)
mydata <- as.data.frame(fit$points)
mydata$sample <- row.names(mydata)
#Plotting MDS
p <- ggplot(mydata,aes(x=V1,y=V2,text=sample)) +
geom_point(size=4, alpha=0.4) +
theme_pubr() +
#scale_colour_manual(values = col_vector, name="Geo tag") +
theme(legend.position = "right") +
xlab('MDS1') + ylab("MDS2")
p
check <- dist(data_matrix, pairwise=TRUE)
# Perform hierarchical clustering
hc <- hclust(check, method = "ward.D")
# Compute silhouette widths for different numbers of clusters
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width
}
# Compute silhouette widths for different numbers of clusters
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, check)$avg.width
}
data_matrix <- as.matrix(data)
# Compute distance matrix
distance_matrix <- dist(data_matrix)
# Check the class of distance_matrix
class(distance_matrix)  # Should be "dist"
# Print a summary of distance_matrix
summary(distance_matrix)  # Verify it's a distance matrix
# Ensure 'distance_matrix' is not an atomic vector
str(distance_matrix)  # Should not show atomic vector
# Perform hierarchical clustering
hc <- hclust(distance_matrix, method = "ward.D")
# Compute silhouette widths for different numbers of clusters
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width
}
data_matrix <- as.matrix(data)
# Compute distance matrix
distance_matrix <- dist(data_matrix)
# Check the class of distance_matrix
class(distance_matrix)  # Should be "dist"
# Print a summary of distance_matrix
summary(distance_matrix)  # Verify it's a distance matrix
# Ensure 'distance_matrix' is not an atomic vector
str(distance_matrix)  # Should not show atomic vector
# Perform hierarchical clustering
hc <- hclust(distance_matrix, method = "ward.D")
# Compute silhouette widths for different numbers of clusters
sil_widths <- c(NA)  # Silhouette width for 1 cluster is NA
# Initialize sil_widths vector
sil_widths <- numeric(10)  # Initialize with length 10, one element for each potential number of clusters
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width
}
}
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
print(i)
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
print(i)
clusters <- cutree(hc, k = i)
print(clusters)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
print(i)
clusters <- cutree(hc, k = i)
sil_widths[i]
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
print(i)
clusters <- cutree(hc, k = i)
print(sil_widths[i])
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Initialize sil_widths vector
sil_widths <- numeric(10)  # Initialize with length 10, one element for each potential number of clusters
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
print(i)
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Compute silhouette widths for different numbers of clusters
sil_widths[0] <- "NA"  # Silhouette width for 1 cluster is NA
# Initialize sil_widths vector
sil_widths <- numeric(10)  # Initialize with length 10, one element for each potential number of clusters
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
print(i)
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Initialize sil_widths vector
sil_widths <- numeric(10)  # Initialize with length 10, one element for each potential number of clusters
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {  # Trying different numbers of clusters from 2 to 10
print(i)
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width}
# Initialize sil_widths as a list
sil_widths <- vector("list", length = 10)
# Compute silhouette widths for different numbers of clusters
for (i in 2:10) {
clusters <- cutree(hc, k = i)
sil_widths[[i]] <- silhouette(clusters, distance_matrix)$avg.width}
for (i in 2:10) {
clusters <- cutree(hc, k = i)
sil_result <- silhouette(clusters, distance_matrix)
print(class(sil_result))
print(str(sil_result))
}
for (i in 2:10) {
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width
}
# Initialize sil_widths as a list
sil_widths <- vector("list", length = 10)
for (i in 2:10) {
clusters <- cutree(hc, k = i)
sil_widths[i] <- silhouette(clusters, distance_matrix)$avg.width
}
# Initialize sil_widths as a list
sil_widths <- vector("list", length = 10)
# Compute silhouette widths for different numbers of clusters
sil_widths <- lapply(2:10, function(i) {
clusters <- cutree(hc, k = i)
silhouette(clusters, distance_matrix)$avg.width
})
# Compute within-cluster sum of squares for different numbers of clusters
for (i in 1:10) {
clusters <- cutree(hc, k = i)
wcss[i] <- sum((distance_matrix)^2 * clusters)
}
# Initialize vector to store within-cluster sum of squares
wcss <- numeric(10)
# Compute within-cluster sum of squares for different numbers of clusters
for (i in 1:10) {
clusters <- cutree(hc, k = i)
wcss[i] <- sum((distance_matrix)^2 * clusters)
}
# Initialize vector to store within-cluster sum of squares
wcss <- numeric(10)
# Compute within-cluster sum of squares for different numbers of clusters
for (i in 1:10) {
clusters <- cutree(hc, k = i)
cluster_centers <- aggregate(as.matrix(distance_matrix), by = list(clusters), FUN = mean)
cluster_wcss <- sum((as.matrix(distance_matrix) - cluster_centers[clusters,])^2)
wcss[i] <- cluster_wcss
}
# Plot the within-cluster sum of squares
plot(1:10, wcss, type = "b", xlab = "Number of clusters", ylab = "Within-cluster sum of squares")
# Find the "elbow point" where the rate of decrease slows down
elbow_point <- elbow_point(wcss)
# Find the "elbow point" where the rate of decrease slows down
elbow_index <- elbow_point(wcss)
# Define elbow_point function
elbow_point <- function(wcss) {
differences <- diff(wcss)
slope <- differences[-1] - differences[-length(differences)]
elbow_index <- which.max(slope) + 1
return(elbow_index)
}
# Find the "elbow point" where the rate of decrease slows down
elbow_index <- elbow_point(wcss)
abline(v = elbow_point, col = "red")
# Plot the within-cluster sum of squares
plot(1:10, wcss, type = "b", xlab = "Number of clusters", ylab = "Within-cluster sum of squares")
# Find the "elbow point" where the rate of decrease slows down
elbow_index <- elbow_point(wcss)
# Plot the vertical line at the elbow point
abline(v = elbow_index, col = "red")
cat("Elbow point:", elbow_index, "\n")
k <- 4  # Change this to your chosen number of clusters
set.seed(123)  # Set seed for reproducibility
kmeans_result <- kmeans(distance_matrix, centers = k)
library(ggrepel)  # For better label placement
# Extract the first two principal components
pc <- prcomp(distance_matrix)$x[, 1:2]
# Create a data frame with PC scores and cluster assignments
df <- data.frame(PC1 = pc[, 1], PC2 = pc[, 2], Cluster = as.factor(kmeans_result$cluster))
# Plot clusters
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_minimal()
# Plot clusters
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_pubr()
# Plot clusters
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_text_repel(aes(label = Cluster), size = 1) +  # Add cluster labels
theme_pubr()
# Plot clusters with contour lines
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_contour(aes(z = Cluster), bins = 5, color = "black", alpha = 0.5) +  # Add contour lines
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_minimal()
# Create a data frame with PC scores and cluster assignments
df <- data.frame(PC1 = pc[, 1], PC2 = pc[, 2], Cluster = as.factor(kmeans_result$cluster))
# Plot clusters with contour lines
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_contour(aes(z = Cluster), bins = 5, color = "black", alpha = 0.5) +  # Add contour lines
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_minimal()
# Extract the first two principal components
pc <- prcomp(distance_matrix)$x[, 1:2]
# Create a data frame with PC scores and cluster assignments
df <- data.frame(PC1 = pc[, 1], PC2 = pc[, 2], Cluster = as.factor(kmeans_result$cluster))
# Plot clusters with contour lines
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_contour(aes(z = Cluster), bins = 5, color = "black", alpha = 0.5) +  # Add contour lines
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_minimal()
k <- 7  # Change this to your chosen number of clusters
set.seed(123)  # Set seed for reproducibility
kmeans_result <- kmeans(distance_matrix, centers = k)
library(ggrepel)  # For better label placement
# Extract the first two principal components
pc <- prcomp(distance_matrix)$x[, 1:2]
# Create a data frame with PC scores and cluster assignments
df <- data.frame(PC1 = pc[, 1], PC2 = pc[, 2], Cluster = as.factor(kmeans_result$cluster))
# Plot clusters
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_pubr()
k <- 2  # Change this to your chosen number of clusters
set.seed(123)  # Set seed for reproducibility
kmeans_result <- kmeans(distance_matrix, centers = k)
library(ggrepel)  # For better label placement
# Extract the first two principal components
pc <- prcomp(distance_matrix)$x[, 1:2]
# Create a data frame with PC scores and cluster assignments
df <- data.frame(PC1 = pc[, 1], PC2 = pc[, 2], Cluster = as.factor(kmeans_result$cluster))
# Plot clusters
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_pubr()
# Gap Statistic
library(cluster)
gap_stat <- clusGap(distance_matrix, kmeans, K.max = 10, B = 50)
# Silhouette Method
sil_widths <- numeric(10)
for (i in 2:10) {
kmeans_result <- kmeans(distance_matrix, centers = i)
sil_widths[i] <- silhouette(kmeans_result$cluster, distance_matrix)$avg.width
}
plot(2:10, sil_widths[2:10], type = "b", xlab = "Number of clusters (k)", ylab = "Average Silhouette Width")
install.packages("NbClust")
library(NbClust)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(distance_matrix, min.nc = 2, max.nc = 10, method = "kmeans", index = "all")
if (any(is.na(distance_matrix))) {
stop("Distance matrix contains missing values. Please handle missing data.")
}
if (any(is.na(distance_matrix))) {
print("Distance matrix contains missing values. Please handle missing data.")
}
?NbClust()
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, diss = NULL, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = NULL, diss = distance_matrix, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, diss = distance_matrix, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = data_matrix, diss = NULL, distance = "euclidean", min.nc = 2, max.nc = 15, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = data_matrix, diss = NULL, distance = "euclidean", min.nc = 2, max.nc = 7, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, diss = NULL, distance = "euclidean", min.nc = 2, max.nc = 7, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, distance = "euclidean", min.nc = 2, max.nc = 7, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, distance = "euclidean", min.nc = 3, max.nc = 7, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, diss = distance_matrix, distance = NULL, min.nc = 3, max.nc = 7, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, diss = distance_matrix, distance = NULL, min.nc = 1, max.nc = 2, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, diss = distance_matrix, distance = NULL, min.nc = 1, max.nc = 2, method = "kmeans", index = "all", alphaBeale = 0.1)
# Use NbClust to compute various indices for different numbers of clusters
nb <- NbClust(data = distance_matrix, diss = distance_matrix, distance = NULL, min.nc = 1, max.nc = 5, method = "kmeans", index = "all", alphaBeale = 0.1)
install.packages("ClusterCrit")
install.packages("clusterCrit")
install.packages("clusterCrit")
install.packages("clusterCrit")
install.packages("clusterCrit")
library(clusterCrit)
install.packages("factoextra")
fviz_nbclust(distance_matrix, FUNcluster = kmeans, method = "wss")
library(factoextra)
fviz_nbclust(distance_matrix, FUNcluster = kmeans, method = "wss")
fviz_nbclust(distance_matrix, kmeans, method = "wss")
# Compute cluster validity indices and visualize
# Use the wss (within-cluster sum of squares) method
# Change distance_matrix to your distance matrix
# You need to provide the number of clusters (k) to compute the within-cluster sum of squares
wss_values <- numeric(10)  # Initialize a vector to store wss values for different k
for (i in 2:10) {
kmeans_model <- kmeans(distance_matrix, centers = i)
wss_values[i] <- kmeans_model$tot.withinss
}
plot(2:10, wss_values, type = "b", xlab = "Number of clusters (k)", ylab = "Within-cluster sum of squares (WSS)",
main = "Elbow Method to Determine Optimal Number of Clusters")
# Compute cluster validity indices and visualize
# Use the wss (within-cluster sum of squares) method
# Change distance_matrix to your distance matrix
# You need to provide the number of clusters (k) to compute the within-cluster sum of squares
# Initialize a vector to store WSS values for different k
wss_values <- numeric(10)
# Compute WSS values for different numbers of clusters (2 to 10)
for (i in 2:10) {
kmeans_model <- kmeans(distance_matrix, centers = i)
wss_values[i] <- kmeans_model$tot.withinss
}
# Plot WSS values against the number of clusters
plot(2:10, wss_values[2:10], type = "b",
xlab = "Number of clusters (k)", ylab = "Within-cluster sum of squares (WSS)",
main = "Elbow Method to Determine Optimal Number of Clusters")
k <- 4  # Change this to your chosen number of clusters
kmeans_result <- kmeans(distance_matrix, centers = k)
# Extract the first two principal components
pc <- prcomp(distance_matrix)$x[, 1:2]
# Create a data frame with PC scores and cluster assignments
df <- data.frame(PC1 = pc[, 1], PC2 = pc[, 2], Cluster = as.factor(kmeans_result$cluster))
# Plot clusters
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_text_repel(aes(label = Cluster), size = 3) +  # Add cluster labels
theme_pubr()
#make sure you set the correct working directory
#change the file name below to address your MSA fasta file
filename <- "AD2_var.fasta"
#clear your environment
rm(list = ls())
